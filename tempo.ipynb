{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP5n5n5K5z5X5v5Y5z5W5x5"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ObjectMatrix/Automotive-Physical-Damage-Claimss/blob/main/courseraSupervised_adjusted.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Insurance Claim Prediction using Supervised Machine Learning\n",
        "\n",
        "## Main Objective of the Analysis\n",
        "The primary objective is to develop a predictive model to determine whether a policyholder will file an insurance claim (`insuranceclaim`), enabling the insurance company to assess risk and adjust premiums proactively. The focus is on **prediction** to optimize financial planning and reduce losses from unexpected claims, while providing **interpretability** to uncover key claim drivers for stakeholders. Benefits include enhanced risk management, improved pricing accuracy, and targeted interventions.\n",
        "\n",
        "## Brief Description of the Data Set\n",
        "The dataset (`Insurance.csv`) contains **1,338 records** of insurance policyholders with **8 attributes**:  \n",
        "- `age`: Age of the policyholder (numeric)  \n",
        "- `sex`: Gender (0=female, 1=male)  \n",
        "- `bmi`: Body Mass Index (numeric)  \n",
        "- `children`: Number of children (numeric)  \n",
        "- `smoker`: Smoking status (0=no, 1=yes)  \n",
        "- `region`: Geographic region (0-3)  \n",
        "- `charges`: Insurance charges (numeric)  \n",
        "- `insuranceclaim`: Target variable (0=no claim, 1=claim)  \n",
        "\n",
        "The goal is to predict `insuranceclaim` and identify key predictors of claim likelihood."
      ],
      "metadata": {
        "id": "kskSYlzSldIO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jupy8KRSDaid"
      },
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "!pip install -q pandas numpy seaborn matplotlib scikit-learn\n",
        "\n",
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# Load data\n",
        "url = 'https://raw.githubusercontent.com/ObjectMatrix/Automotive-Physical-Damage-Claimss/main/Insurance.csv'\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Basic EDA\n",
        "print('First 5 rows:')\n",
        "print(df.head())\n",
        "print('\\nData Info:')\n",
        "print(df.info())\n",
        "print('\\nData Description:')\n",
        "print(df.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Brief Summary of Data Exploration and Actions Taken\n",
        "Exploration revealed no missing values in the dataset. Outliers in `charges` were capped at the 99th percentile to mitigate extreme values. A new feature, `charges_per_child` (`charges` / (`children` + 1)), was engineered to capture cost per dependent, avoiding division by zero. Numerical features (`age`, `bmi`, `children`, `charges`, `charges_per_child`) were scaled using StandardScaler. Visualizations confirmed `smoker` and `charges` as potential claim predictors."
      ],
      "metadata": {
        "id": "Xauc7C9ojQ0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "print('Missing Values:')\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Handle outliers\n",
        "df['charges'] = df['charges'].clip(upper=df['charges'].quantile(0.99))\n",
        "\n",
        "# Feature engineering\n",
        "df['charges_per_child'] = df['charges'] / (df['children'] + 1)\n",
        "\n",
        "# Visualizations\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.histplot(df['charges'], kde=True)\n",
        "plt.title('Distribution of Insurance Charges')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.boxplot(x='smoker', y='charges', hue='insuranceclaim', data=df)\n",
        "plt.title('Charges vs. Smoker Status by Insurance Claim')\n",
        "plt.show()\n",
        "\n",
        "# Prepare features and target\n",
        "X = df.drop('insuranceclaim', axis=1)\n",
        "y = df['insuranceclaim']\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "ubCg-9_vjTOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary of Training Classifier Models\n",
        "Three classifier models were trained using an 80/20 train-test split and 5-fold cross-validation:\n",
        "- **Logistic Regression**: Baseline model with high interpretability.\n",
        "- **Random Forest**: Ensemble model (100 trees) capturing complex interactions.\n",
        "- **Gradient Boosting**: Tuned model (learning_rate=0.1, max_depth=4) for high accuracy.\n",
        "\n",
        "Models were evaluated on accuracy and F1-score to balance precision and recall."
      ],
      "metadata": {
        "id": "MFUDnM8QRcV-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define models\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(random_state=42),\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(learning_rate=0.1, max_depth=4, random_state=42)\n",
        "}\n",
        "\n",
        "# Train and evaluate\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    cv_scores = cross_val_score(model, X_scaled, y, cv=5, scoring='accuracy')\n",
        "    results[name] = {'Accuracy': acc, 'F1-Score': f1, 'CV Accuracy': cv_scores.mean()}\n",
        "    print(f'{name}:')\n",
        "    print(f'  Accuracy = {acc:.2f}')\n",
        "    print(f'  F1-Score = {f1:.2f}')\n",
        "    print(f'  CV Accuracy = {cv_scores.mean():.2f} Â± {cv_scores.std():.2f}')"
      ],
      "metadata": {
        "id": "d55D7iYFDtqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recommended Final Model\n",
        "The **Gradient Boosting** model is recommended due to its superior accuracy and F1-score, while providing feature importance insights (e.g., `smoker`, `charges`). It balances predictive power and explainability, making it ideal for risk assessment and pricing optimization."
      ],
      "metadata": {
        "id": "3fZnKFajNuJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature importance for Gradient Boosting\n",
        "gb_model = models['Gradient Boosting']\n",
        "importances = pd.Series(gb_model.feature_importances_, index=X.columns)\n",
        "importances.sort_values().plot(kind='barh', figsize=(8, 6))\n",
        "plt.title('Feature Importance (Gradient Boosting)')\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "meibrLkPNu62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary Key Findings and Insights\n",
        "The Gradient Boosting model identified `smoker`, `charges`, and `age` as key drivers of `insuranceclaim`. Smokers were significantly more likely to file claims, with high `charges` also strongly correlated with claim likelihood. Older policyholders showed increased claim tendencies, possibly due to health-related risks. These insights suggest focusing on smoking status and premium levels for risk management.\n",
        "\n",
        "## Suggestions for Next Steps\n",
        "- **Add Features**: Include health data (e.g., medical history) or regional risk factors to improve predictions.\n",
        "- **Address Imbalance**: Use SMOTE if `insuranceclaim` imbalance impacts performance.\n",
        "- **Deploy Model**: Pilot the Gradient Boosting model in pricing strategies to assess real-world efficacy.\n",
        "- **Explore Alternatives**: Test neural networks for potentially higher accuracy, though with reduced interpretability."
      ],
      "metadata": {
        "id": "2CXWCnpjNvKi"
      }
    }
  ]
}
