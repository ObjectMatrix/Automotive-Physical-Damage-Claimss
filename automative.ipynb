{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/ObjectMatrix/Automotive-Physical-Damage-Claimss/blob/main/automative.ipynb",
      "authorship_tag": "ABX9TyNH6SeclKRci2wA7TpSt/qY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ObjectMatrix/Automotive-Physical-Damage-Claimss/blob/main/automative.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import nexessary libs"
      ],
      "metadata": {
        "id": "I-VIUlM10l5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "lUVrQXaf3wXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "# For data augmentation while data preprocessing\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Pretrained MobileNet model.\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "\n",
        "# Performing MaxPooling operations\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "\n",
        "# For performing dropout operation\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "# For flattening operation\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Input() is used to instantiate a Keras tensor.\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# We use adam optimizer\n",
        "from tensorflow.keras.optimizers.legacy import Adam\n",
        "\n",
        "# Preprocesses a tensor or Numpy array encoding a batch of images.\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "\n",
        "# Converts a PIL Image instance to a Numpy array.\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "\n",
        "# Loads an image into PIL format.\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "\n",
        "# Converts a class vector (integers) to binary class matrix.\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Binarize labels in a one-vs-all fashion.\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "# Performing train-test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# For printing the metrics\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# For using strings in file structure path format\n",
        "from imutils import paths\n",
        "\n",
        "# For plotting losse functions\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# For performing mathematical computations\n",
        "import numpy as np\n",
        "\n",
        "# For file-related operations\n",
        "import os"
      ],
      "metadata": {
        "id": "alf8VKXw3JF4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "FvC1f1pFGHBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to directory containing data\n",
        "DataDir = \"/content/drive/MyDrive/input/car-damage-detection/data1a\"\n",
        "# Path to training directory\n",
        "train_dir = os.path.join(DataDir, 'training/')\n",
        "\n",
        "# Path to validation directory\n",
        "val_dir = os.path.join(DataDir, 'validation/')\n",
        "\n",
        "# Path for damaged training images\n",
        "train_damage = os.path.join(train_dir, '00-damage')\n",
        "# Path for training images not damaged\n",
        "train_not_damage = os.path.join(val_dir, '01-whole')\n",
        "\n",
        "# Number of damaged training images\n",
        "num_train_damage = len(os.listdir(train_damage))\n",
        "\n",
        "# Number of training images not damaged\n",
        "num_train_not_damage = len(os.listdir(train_not_damage))\n",
        "\n",
        "# Path for damaged validation\n",
        "val_damage = os.path.join(val_dir, '00-damage')\n",
        "\n",
        "# Path for validation images not damaged\n",
        "val_not_damage = os.path.join(val_dir, '01-whole')\n",
        "\n",
        "# Number of damaged validation images\n",
        "num_val_damage = len(os.listdir(val_damage))\n",
        "\n",
        "# Number of validation images not damaged\n",
        "num_val_not_damage = len(os.listdir((val_not_damage)))\n",
        "\n",
        "# Number of training images\n",
        "num_train = num_train_damage + num_train_not_damage\n",
        "\n",
        "# Number of validation images\n",
        "num_val = num_val_damage + num_val_not_damage\n",
        "\n",
        "\n",
        "# Total images\n",
        "total_images = num_val + num_train\n",
        "print(\"Total training images\",num_train)\n",
        "print(\"Total training images (Damaged)\", num_train_damage)\n",
        "print(\"Total training images (Damaged)\", num_train_not_damage)\n",
        "print()\n",
        "\n",
        "print(\"Total validation images\", num_val)\n",
        "print(\"Total training images (Damaged)\", num_val_damage)\n",
        "print(\"Total training images (Damaged)\", num_val_not_damage)\n",
        "print()\n",
        "\n",
        "print(\"Total Number of Images: \",total_images)\n",
        "\n",
        "# Plotting a sample image\n",
        "plt.grid('')\n",
        "image = plt.imread('/content/drive/MyDrive/input/car-damage-detection/data1a/training/01-whole/0195.jpg')\n",
        "plt.imshow(image)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rZTjR3aKFWRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initializing the hyperparameters\n",
        "initial_lr = 0.001\n",
        "epochs = 100\n",
        "batch_size = 64\n",
        "\n",
        "# Classes which are detected\n",
        "classes = [\"00-damage\", \"01-whole\"]"
      ],
      "metadata": {
        "id": "6S-OdeocIaXv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grab the list of images in our dataset directory, then initialize\n",
        "# the list of data (i.e., images) and class images\n",
        "print(\"[INFO] loading images...\")\n",
        "\n",
        "# It stores the data or feature set\n",
        "data = []\n",
        "\n",
        "# It stores the corrosponding labels\n",
        "labels = []\n",
        "\n",
        "for class_ in classes:\n",
        "    path = os.path.join(train_dir, class_)\n",
        "    for image in os.listdir(path):\n",
        "    \timage_path = os.path.join(path, image)\n",
        "    \timage_ = load_img(image_path, target_size=(224, 224))\n",
        "    \timage_ = img_to_array(image_)\n",
        "    \timage_ = preprocess_input(image_)\n",
        "\n",
        "    \tdata.append(image_)\n",
        "    \tlabels.append(class_)\n",
        "\n",
        "\n",
        "for class_ in classes:\n",
        "    path = os.path.join(val_dir, class_)\n",
        "    for image in os.listdir(path):\n",
        "    \timage_path = os.path.join(path, image)\n",
        "    \timage_ = load_img(image_path, target_size=(224, 224))\n",
        "    \timage_ = img_to_array(image_)\n",
        "    \timage_ = preprocess_input(image_)\n",
        "\n",
        "    \tdata.append(image_)\n",
        "    \tlabels.append(class_)\n",
        "\n",
        "# perform one-hot encoding on the labels\n",
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(labels)\n",
        "labels = to_categorical(labels)\n",
        "\n",
        "data = np.array(data, dtype=\"float32\")\n",
        "labels = np.array(labels)\n",
        "\n",
        "\n",
        "\n",
        "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
        "\ttest_size=0.20, stratify=labels, random_state=42)\n",
        "# construct the training image generator for data augmentation\n",
        "aug = ImageDataGenerator(\n",
        "\trotation_range=20,\n",
        "\tzoom_range=0.15,\n",
        "\twidth_shift_range=0.2,\n",
        "\theight_shift_range=0.2,\n",
        "\tshear_range=0.15,\n",
        "\thorizontal_flip=True,\n",
        "\tfill_mode=\"nearest\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75tecQIHI1WC",
        "outputId": "ca170558-b9bf-425d-8a36-44581ad9de67"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] loading images...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the MobileNetV2 network, ensuring the topmost fully-connected\n",
        "# layer sets are left off\n",
        "model_base = MobileNetV2(weights=\"imagenet\", include_top=False,\n",
        "\tinput_tensor=Input(shape=(224, 224, 3)))\n",
        "# Constructing the top architecture of our model, which is placed over the\n",
        "# pretrained model\n",
        "model_head = model_base.output\n",
        "# MaxPooling layer\n",
        "\n",
        "model_head = MaxPooling2D(pool_size=(5, 5))(model_head)\n",
        "# Flatten layer\n",
        "model_head = Flatten(name=\"flatten\")(model_head)\n",
        "\n",
        "# Activation function relu\n",
        "model_head = Dense(128, activation=\"relu\")(model_head)\n",
        "\n",
        "# Performing dropout\n",
        "model_head = Dropout(0.5)(model_head)\n",
        "\n",
        "# Final output layer consists of softmax layer\n",
        "model_head = Dense(2, activation=\"softmax\")(model_head)\n",
        "\n",
        "# place the head FC model on top of the base model (this will become\n",
        "# the actual model we will train)\n",
        "model_final = Model(inputs=model_base.input, outputs=model_head)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KgDGfVHJLap",
        "outputId": "2f29e4a3-132e-496a-e80d-25fb52eb2b88"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# looping over all the layers and setting each individual layer trainability\n",
        "# to false.\n",
        "for layer in model_base.layers:\n",
        "\tlayer.trainable = False\n",
        "\n",
        "# Setting optimizer to Adam\n",
        "optim = Adam(lr=initial_lr, decay=initial_lr / epochs)\n",
        "\n",
        "# Compiling our model\n",
        "model_final.compile(loss=\"binary_crossentropy\", optimizer=optim,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "# train the head of the network\n",
        "model_train = model_final.fit(\n",
        "#     Generates image generator from ImageGeneratorClass for inputing images in batches\n",
        "\taug.flow(trainX, trainY, batch_size=batch_size),\n",
        "#     Number of steps to be taken in one epoch over image batches\n",
        "\tsteps_per_epoch=len(trainX) // batch_size,\n",
        "#     Validation data\n",
        "\tvalidation_data=(testX, testY),\n",
        "\n",
        "#     Steps for validation data\n",
        "\tvalidation_steps=len(testX) // batch_size,\n",
        "\n",
        "#     Number of epochs\n",
        "\tepochs=epochs)"
      ],
      "metadata": {
        "id": "XFFaEo1sJS4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, we predict on test set.\n",
        "predict = model_final.predict(testX, batch_size=batch_size)\n",
        "\n",
        "# for each image in the test set we find the index of the\n",
        "# label with corresponding largest predicted probability\n",
        "predict_index = np.argmax(predict, axis=1)\n",
        "\n",
        "# Displaying classification report\n",
        "print(classification_report(testY.argmax(axis=1), predict_index,\n",
        "\ttarget_names=lb.classes_))\n",
        "\n",
        "model_save_path = \"/content/drive/MyDrive/my_car_model/Car_detection.model\"\n",
        "model_final.save(model_save_path, save_format=\"h5\")\n",
        "\n",
        "# Storing our model for further use.\n",
        "# model_final.save(\"Car_detection.model\", save_format=\"h5\")"
      ],
      "metadata": {
        "id": "qLqsoaZ7N3sC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2312e96b-917c-4f51-e2ad-694ad252ff23"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 21s 2s/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   00-damage       0.93      0.83      0.88       230\n",
            "    01-whole       0.85      0.94      0.89       230\n",
            "\n",
            "    accuracy                           0.88       460\n",
            "   macro avg       0.89      0.88      0.88       460\n",
            "weighted avg       0.89      0.88      0.88       460\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting training loss and accuracy\n",
        "num = epochs\n",
        "\n",
        "# matplotlib style\n",
        "plt.style.use(\"seaborn\")\n",
        "plt.figure()\n",
        "\n",
        "# Plotting all the required quantities\n",
        "# Train Accuracy\n",
        "plt.plot(np.arange(0, num), model_train.history[\"accuracy\"], label=\"Train Accuracy\")\n",
        "\n",
        "# Validation Accuracy\n",
        "plt.plot(np.arange(0, num), model_train.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
        "\n",
        "# Train Loss\n",
        "plt.plot(np.arange(0, num), model_train.history[\"loss\"], label=\"Train Loss\")\n",
        "\n",
        "# Validation Loss\n",
        "plt.plot(np.arange(0, num), model_train.history[\"val_loss\"], label=\"Validation Loss\")\n",
        "\n",
        "# Setting the title\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "\n",
        "# Setting the label\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy/Loss\")\n",
        "plt.legend(loc=\"upper right\")\n",
        "\n",
        "# Saving the Model\n",
        "plt.savefig(\"Car_Detection.png\")"
      ],
      "metadata": {
        "id": "j0tNDdfvOHEb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}