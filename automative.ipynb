{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/ObjectMatrix/Automotive-Physical-Damage-Claimss/blob/main/automative.ipynb",
      "authorship_tag": "ABX9TyO9guZpY4H3x26OAn54NbNX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ObjectMatrix/Automotive-Physical-Damage-Claimss/blob/main/automative.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import nexessary libs"
      ],
      "metadata": {
        "id": "I-VIUlM10l5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "lUVrQXaf3wXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "# For data augmentation while data preprocessing\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Pretrained MobileNet model.\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "\n",
        "# Performing MaxPooling operations\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "\n",
        "# For performing dropout operation\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "# For flattening operation\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Input() is used to instantiate a Keras tensor.\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# We use adam optimizer\n",
        "from tensorflow.keras.optimizers.legacy import Adam\n",
        "\n",
        "# Preprocesses a tensor or Numpy array encoding a batch of images.\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "\n",
        "# Converts a PIL Image instance to a Numpy array.\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "\n",
        "# Loads an image into PIL format.\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "\n",
        "# Converts a class vector (integers) to binary class matrix.\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Binarize labels in a one-vs-all fashion.\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "# Performing train-test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# For printing the metrics\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# For using strings in file structure path format\n",
        "from imutils import paths\n",
        "\n",
        "# For plotting losse functions\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# For performing mathematical computations\n",
        "import numpy as np\n",
        "\n",
        "# For file-related operations\n",
        "import os"
      ],
      "metadata": {
        "id": "alf8VKXw3JF4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "FvC1f1pFGHBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to directory containing data\n",
        "DataDir = \"/content/drive/MyDrive/input/car-damage-detection/data1a\"\n",
        "# Path to training directory\n",
        "train_dir = os.path.join(DataDir, 'training/')\n",
        "\n",
        "# Path to validation directory\n",
        "val_dir = os.path.join(DataDir, 'validation/')\n",
        "\n",
        "# Path for damaged training images\n",
        "train_damage = os.path.join(train_dir, '00-damage')\n",
        "# Path for training images not damaged\n",
        "train_not_damage = os.path.join(val_dir, '01-whole')\n",
        "\n",
        "# Number of damaged training images\n",
        "num_train_damage = len(os.listdir(train_damage))\n",
        "\n",
        "# Number of training images not damaged\n",
        "num_train_not_damage = len(os.listdir(train_not_damage))\n",
        "\n",
        "# Path for damaged validation\n",
        "val_damage = os.path.join(val_dir, '00-damage')\n",
        "\n",
        "# Path for validation images not damaged\n",
        "val_not_damage = os.path.join(val_dir, '01-whole')\n",
        "\n",
        "# Number of damaged validation images\n",
        "num_val_damage = len(os.listdir(val_damage))\n",
        "\n",
        "# Number of validation images not damaged\n",
        "num_val_not_damage = len(os.listdir((val_not_damage)))\n",
        "\n",
        "# Number of training images\n",
        "num_train = num_train_damage + num_train_not_damage\n",
        "\n",
        "# Number of validation images\n",
        "num_val = num_val_damage + num_val_not_damage\n",
        "\n",
        "\n",
        "# Total images\n",
        "total_images = num_val + num_train\n",
        "print(\"Total training images\",num_train)\n",
        "print(\"Total training images (Damaged)\", num_train_damage)\n",
        "print(\"Total training images (Damaged)\", num_train_not_damage)\n",
        "print()\n",
        "\n",
        "print(\"Total validation images\", num_val)\n",
        "print(\"Total training images (Damaged)\", num_val_damage)\n",
        "print(\"Total training images (Damaged)\", num_val_not_damage)\n",
        "print()\n",
        "\n",
        "print(\"Total Number of Images: \",total_images)\n",
        "\n",
        "# Plotting a sample image\n",
        "plt.grid('')\n",
        "image = plt.imread('/content/drive/MyDrive/input/car-damage-detection/data1a/training/01-whole/0195.jpg')\n",
        "plt.imshow(image)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rZTjR3aKFWRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initializing the hyperparameters\n",
        "initial_lr = 0.001\n",
        "epochs = 100\n",
        "batch_size = 64\n",
        "\n",
        "# Classes which are detected\n",
        "classes = [\"00-damage\", \"01-whole\"]"
      ],
      "metadata": {
        "id": "6S-OdeocIaXv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grab the list of images in our dataset directory, then initialize\n",
        "# the list of data (i.e., images) and class images\n",
        "print(\"[INFO] loading images...\")\n",
        "\n",
        "# It stores the data or feature set\n",
        "data = []\n",
        "\n",
        "# It stores the corrosponding labels\n",
        "labels = []\n",
        "\n",
        "for class_ in classes:\n",
        "    path = os.path.join(train_dir, class_)\n",
        "    for image in os.listdir(path):\n",
        "    \timage_path = os.path.join(path, image)\n",
        "    \timage_ = load_img(image_path, target_size=(224, 224))\n",
        "    \timage_ = img_to_array(image_)\n",
        "    \timage_ = preprocess_input(image_)\n",
        "\n",
        "    \tdata.append(image_)\n",
        "    \tlabels.append(class_)\n",
        "\n",
        "\n",
        "for class_ in classes:\n",
        "    path = os.path.join(val_dir, class_)\n",
        "    for image in os.listdir(path):\n",
        "    \timage_path = os.path.join(path, image)\n",
        "    \timage_ = load_img(image_path, target_size=(224, 224))\n",
        "    \timage_ = img_to_array(image_)\n",
        "    \timage_ = preprocess_input(image_)\n",
        "\n",
        "    \tdata.append(image_)\n",
        "    \tlabels.append(class_)\n",
        "\n",
        "# perform one-hot encoding on the labels\n",
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(labels)\n",
        "labels = to_categorical(labels)\n",
        "\n",
        "data = np.array(data, dtype=\"float32\")\n",
        "labels = np.array(labels)\n",
        "\n",
        "\n",
        "\n",
        "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
        "\ttest_size=0.20, stratify=labels, random_state=42)\n",
        "# construct the training image generator for data augmentation\n",
        "aug = ImageDataGenerator(\n",
        "\trotation_range=20,\n",
        "\tzoom_range=0.15,\n",
        "\twidth_shift_range=0.2,\n",
        "\theight_shift_range=0.2,\n",
        "\tshear_range=0.15,\n",
        "\thorizontal_flip=True,\n",
        "\tfill_mode=\"nearest\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75tecQIHI1WC",
        "outputId": "ca170558-b9bf-425d-8a36-44581ad9de67"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] loading images...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the MobileNetV2 network, ensuring the topmost fully-connected\n",
        "# layer sets are left off\n",
        "model_base = MobileNetV2(weights=\"imagenet\", include_top=False,\n",
        "\tinput_tensor=Input(shape=(224, 224, 3)))\n",
        "# Constructing the top architecture of our model, which is placed over the\n",
        "# pretrained model\n",
        "model_head = model_base.output\n",
        "# MaxPooling layer\n",
        "\n",
        "model_head = MaxPooling2D(pool_size=(5, 5))(model_head)\n",
        "# Flatten layer\n",
        "model_head = Flatten(name=\"flatten\")(model_head)\n",
        "\n",
        "# Activation function relu\n",
        "model_head = Dense(128, activation=\"relu\")(model_head)\n",
        "\n",
        "# Performing dropout\n",
        "model_head = Dropout(0.5)(model_head)\n",
        "\n",
        "# Final output layer consists of softmax layer\n",
        "model_head = Dense(2, activation=\"softmax\")(model_head)\n",
        "\n",
        "# place the head FC model on top of the base model (this will become\n",
        "# the actual model we will train)\n",
        "model_final = Model(inputs=model_base.input, outputs=model_head)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KgDGfVHJLap",
        "outputId": "2f29e4a3-132e-496a-e80d-25fb52eb2b88"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# looping over all the layers and setting each individual layer trainability\n",
        "# to false.\n",
        "for layer in model_base.layers:\n",
        "\tlayer.trainable = False\n",
        "\n",
        "# Setting optimizer to Adam\n",
        "optim = Adam(lr=initial_lr, decay=initial_lr / epochs)\n",
        "\n",
        "# Compiling our model\n",
        "model_final.compile(loss=\"binary_crossentropy\", optimizer=optim,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "# train the head of the network\n",
        "model_train = model_final.fit(\n",
        "#     Generates image generator from ImageGeneratorClass for inputing images in batches\n",
        "\taug.flow(trainX, trainY, batch_size=batch_size),\n",
        "#     Number of steps to be taken in one epoch over image batches\n",
        "\tsteps_per_epoch=len(trainX) // batch_size,\n",
        "#     Validation data\n",
        "\tvalidation_data=(testX, testY),\n",
        "\n",
        "#     Steps for validation data\n",
        "\tvalidation_steps=len(testX) // batch_size,\n",
        "\n",
        "#     Number of epochs\n",
        "\tepochs=epochs)"
      ],
      "metadata": {
        "id": "XFFaEo1sJS4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, we predict on test set.\n",
        "predict = model_final.predict(testX, batch_size=batch_size)\n",
        "\n",
        "# for each image in the test set we find the index of the\n",
        "# label with corresponding largest predicted probability\n",
        "predict_index = np.argmax(predict, axis=1)\n",
        "\n",
        "# Displaying classification report\n",
        "print(classification_report(testY.argmax(axis=1), predict_index,\n",
        "\ttarget_names=lb.classes_))\n",
        "\n",
        "model_save_path = \"/content/drive/MyDrive/my_car_model/Car_detection.model\"\n",
        "model_final.save(model_save_path, save_format=\"h5\")\n",
        "\n",
        "# Storing our model for further use.\n",
        "# model_final.save(\"Car_detection.model\", save_format=\"h5\")"
      ],
      "metadata": {
        "id": "qLqsoaZ7N3sC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TEST MODEL HERE\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "\n",
        "#image_path = \"/content/drive/MyDrive/input/car-damage-detection/data1a/validation/00-damage/0005.JPEG\"\n",
        "image_path = \"/content/drive/MyDrive/input/car-damage-detection/data1a/validation/01-whole/dent.jpg\"\n",
        "# Load the image with the right target size for your model\n",
        "image = load_img(image_path, target_size=(224, 224))\n",
        "\n",
        "# Convert the image to a numpy array\n",
        "image_array = img_to_array(image)\n",
        "\n",
        "# Add a new axis to make the array match the model's input shape\n",
        "image_array = np.expand_dims(image_array, axis=0)\n",
        "\n",
        "# Use the appropriate preprocess input function for your model architecture\n",
        "image_array = preprocess_input(image_array)\n",
        "\n",
        "prediction = model_final.predict(image_array)\n",
        "\n",
        "# Assuming your model's final layer is a softmax, the prediction will be a 2-element array\n",
        "print(prediction)\n",
        "\n",
        "# Decode the prediction\n",
        "predicted_class_index = np.argmax(prediction, axis=1)[0]\n",
        "classes = [\"Damaged\", \"Not Damaged\"]  # Ensure this matches the classes used during training\n",
        "print(f\"Predicted class: {classes[predicted_class_index]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bag01T5OXyXG",
        "outputId": "ec8fbf4c-7527-448a-a1b6-9fe22465f0ba"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 107ms/step\n",
            "[[0.9988201  0.00117982]]\n",
            "Predicted class: Damaged\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting training loss and accuracy\n",
        "num = epochs\n",
        "\n",
        "# matplotlib style\n",
        "plt.style.use(\"seaborn\")\n",
        "plt.figure()\n",
        "\n",
        "# Plotting all the required quantities\n",
        "# Train Accuracy\n",
        "plt.plot(np.arange(0, num), model_train.history[\"accuracy\"], label=\"Train Accuracy\")\n",
        "\n",
        "# Validation Accuracy\n",
        "plt.plot(np.arange(0, num), model_train.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
        "\n",
        "# Train Loss\n",
        "plt.plot(np.arange(0, num), model_train.history[\"loss\"], label=\"Train Loss\")\n",
        "\n",
        "# Validation Loss\n",
        "plt.plot(np.arange(0, num), model_train.history[\"val_loss\"], label=\"Validation Loss\")\n",
        "\n",
        "# Setting the title\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "\n",
        "# Setting the label\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy/Loss\")\n",
        "plt.legend(loc=\"upper right\")\n",
        "\n",
        "# Saving the Model\n",
        "plt.savefig(\"Car_Detection.png\")"
      ],
      "metadata": {
        "id": "j0tNDdfvOHEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To enable a model to identify specific types of car damage (e.g., dents, scratches, shattered windows), you would need to:\n",
        "\n",
        "Collect and Label a More Detailed Dataset: You would need a dataset that includes images of cars with various types of damage, each labeled according to the type of damage it exhibits. The dataset should be diverse and cover all the types of damage you want the model to recognize.\n",
        "\n",
        "Design a Model for Multi-Class Classification: Modify the existing model or design a new model that can handle multi-class classification. This involves changing the final layer of the model to have as many neurons as there are damage types (classes) and using a softmax activation function. The loss function typically used for multi-class classification is categorical_crossentropy.\n",
        "\n",
        "Train the Model on the Detailed Dataset: Train the model on the new dataset. This will require splitting the dataset into training, validation, and test sets, performing data augmentation (if necessary), and then training the model using these sets.\n",
        "\n",
        "Evaluate and Adjust the Model: Evaluate the model's performance using the test set and, if necessary, adjust the model's architecture, hyperparameters, or training procedure to improve its ability to accurately classify different types of damage.\n",
        "\n",
        "Here is a simplified example of how the final layer of the model might be adjusted for multi-class classification to identify different types of damage:\n",
        "\n",
        "# Assuming 'model_base' is the base MobileNetV2 model\n",
        "\n",
        "# Adjust the model head for multi-class classification\n",
        "model_head = Flatten(name=\"flatten\")(model_base.output)\n",
        "model_head = Dense(128, activation=\"relu\")(model_head)\n",
        "model_head = Dropout(0.5)(model_head)\n",
        "\n",
        "# Adjust the number of neurons in the final layer to match the number of classes\n",
        "# For example, if there are 5 types of damage, set the final Dense layer to have 5 neurons\n",
        "num_classes = 5  # Adjust this to match the number of damage types in your dataset\n",
        "model_head = Dense(num_classes, activation=\"softmax\")(model_head)\n",
        "\n",
        "# Create the final model\n",
        "model_final = Model(inputs=model_base.input, outputs=model_head)"
      ],
      "metadata": {
        "id": "uxI1OBbkpPpR"
      }
    }
  ]
}